---
title: 'STAT 300: Written Assignment 2'
author: 'Aronn Grant Laurel (21232475)'
date: "April, 2025"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#if you do not have the package, type install.packages("name_of_the_package")
library(knitr)
library(zoo)
library(ggplot2)
```

### Question 1

(a) 

```{r, echo=TRUE}
student <- read.csv("students_data.csv", header = TRUE)
# head(student)

# Boxplot
ggplot(student, aes(x = TrainingMethod, y = ExamScore, fill = TrainingMethod)) +
  geom_boxplot() +
  labs(title = "Exam Score Distribution by Training Method",
       x = "Training Method",
       y = "Exam Score") +
  theme_minimal()

```
For our boxplot, In-Person Classes hold the highest median score and a relatively
wider inter-quartile range. Self-Study Method holdes the lowest median score while
Online Courses seem to have a smaller inter-quartile range. Overall,
students under the In-person class method seem to perform better on average.



```{r, echo=TRUE}
# Scatterplot
ggplot(student, aes(x = StudyHours, y = ExamScore, color = PreviousGPA)) +
  geom_point(alpha = 0.7) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(title = "Study Hours vs. Exam Score (Colored by Previous GPA)",
       x = "Study Hours",
       y = "Exam Score",
       color = "Previous GPA") +
  theme_minimal()
```
Overall, we can observe a slight positive correlation between exam scores
and study hours. Furthermore, we can see that higher GPA holders (3.5 - 4.0) tend to
cluster at the upper right of the graph with high exam score and study hours. 
On the other hand, lower GPA holders (3.0 - 0) tend to be at the bottom right
of the scatterplot whose students have lower exam scores and study hours.
Therefore, we can say that students who have higher exam scores.


(b)

```{r, echo=TRUE}
student$TrainingMethod <- as.factor(student$TrainingMethod)
model <- lm(ExamScore ~ StudyHours + PreviousGPA + TrainingMethod, data = student)
summary(model)

```

$\ Exam Score = 46.3115 + 1.0688*(Study Hours) + 5.3071*(Previous GPA) - 2.8668*(Online Course) - 6.6728*(Self-Study) + epsilon$

For Coefficient: Study Hours
For an increase of 1 studying hour per week, we expect an increase in exam 
score by approximately 1.06 points

For Coefficient: PreviousGPA
For an increase of 1 Previous GPA point, we expect an increase in exam 
score by approximately 5.31 points

For Coefficient: TrainingMethod - Online Course
For students taking Online Course, they average 2.87 points lower on the exam
compared to those who attended In-person classes

For Coefficient: TrainingMethod - Self Study
For students who Self Studied, they average 6.67 points lower on the exam
compared to those who attended In-person classes

(c)
Given:
Study Hours per week = 8
Previous GPA = 3.8
Online Course = 1
Self Study = 0

```{r, echo=TRUE}
46.3115 + 1.0688*(8) + 5.3071*(3.8) - 2.8668*(1) - 6.6728*(0)
```
Therefore, this student's expected exam score is ~ 72.16

(d)
Null Hypothesis
The mean exam scores are equal across all methods
$\  H_0 : \mu_{Self Study} = \mu_{Online class} = \mu_{In Person}$

Alternative Hypothesis
At least one training method has a different mean exam score

```{r, echo=TRUE}
student$TrainingMethod <- as.factor(student$TrainingMethod)
anova_model <- aov(ExamScore ~ TrainingMethod, data = student)
summary(anova_model)

```
As we observe a small p-value 1.16e-10 for our categorical variable - Training
Method, we can reject the null hypothesis at 0.05 significance level. Therefore,
training methods is significant on exam scores.

(e)
```{r, echo=TRUE, fig.height = 7}
par(mfrow = c(2, 2))
plot(model)

```
Residual vs Fitted Plot: we can see no patterns which suggests Linearity  
and non-funneling and constant variance which suggests Homoscedasticity.

Normal Q-Q plot: We can see that our points roughly follows the 'normal'
diagonal line but with heavier tails and skewed, 
thus suggesting that the residuals may not be normally distributed (CLT Theorem).


(f)
```{r, echo=TRUE}
int_model <- lm(ExamScore ~ StudyHours * PreviousGPA + TrainingMethod, data = student)
summary(int_model)

summary(model)

AIC(model, int_model)

```
Looking at the p-values for the interaction term, we can see that it is a
higher pvalue at 0.3718 which is statistically insignificant and that
adding the interaction term may not be necessary. 

Furthermore, we can see that the Adjusted R-Squared between the two models
are very similar with the interaction model being higher by 0.0003.

We can also examine their AIC values to see the better model, and we can observe a 
lower AIC value for our linear model without interaction, thus suggesting that the 
interaction model may be a more insignificant explanatory variable. 

### Question 2
(a) 
```{r, echo=TRUE}
data <- read.csv("data.csv")

# Scatterplot Matrix
ggpairs(data,
        diag = list(continuous = "barDiag"),
        lower = list(continuous = "points"),
        upper = list(continuous = "cor"))

```
We can observe a strong correlation between Temperature and Concentration with 0.976
while the other relationship between other variables seems weaker with less than 0.1.
Looking at the scatter plots, we can observe a linear positive increasing pattern between
Temperature and Concentration while the other scatter plots seem more Non-linear without 
any obvious pattern.

(b)
```{r, echo=TRUE}
model_b <- lm(Concentration ~ Temp + pH, data = data)

summary(model_b)
```
The model equation is: $/ Concentration = 0.3701 + 3.6394(Temp) - 2.4722(pH) $

Coefficient Interpretations:
Temperature: For an increase in 1 Degree Celcius, we expect an increase in
pollutant concentration by 3.6394 units

pH: For an increase in 1 pH Level, we expect a decrease in pollutant concentration
by 2.4722 units

(c) A linear model seems appropriate because the scatter plot between Temperature
and Concentration displays a strong positive linear pattern. Our histograms
also do not have any obvious outliers that would suggest a more complex model.
Also looking into the p-value and Adjusted R-squared of our linear model,
I believe that it is adequate in capturing the relationship.

(d)
Since we have already fitted an Additive linear regression, we will extend
the model by applying an interaction term between Temperature and pH :

```{r, echo=TRUE}
model_d <- lm(Concentration ~ Temp * pH, data = data)

summary(model_d)
```
The model equation is: $/ Concentration = 2.93433 + 3.45312(Temp) - 2.82304(pH) + 0.02532 (Temp)(pH) $

Coefficient Interpretations:
Temperature: For an increase in 1 Degree Celcius, we expect an increase in
pollutant concentration by 3.45312 units

pH: For an increase in 1 pH Level, we expect a decrease in pollutant concentration
by 2.82304 units

Interaction Term: For an increase by 1 unit in both Temperature and pH Level, 
we expect an increase in pollutant concentration by 0.02532 units

Given the interaction's p-value to be quite high with 0.85422, that suggests that
the interaction term is not statistically significant at confidence level 5%. 
This suggests that including the interaction may not meaningfully improve the model.

(e)
```{r, echo=TRUE}
# R squared
summary(model_b)$r.squared
summary(model_d)$r.squared

# Adjusted R squared
summary(model_b)$adj.r.squared
summary(model_d)$adj.r.squared
```
In terms of R squared, both models explained about 95.55% of the variation with
the interaction model explaining better than our additive model by slightly more
with a difference of 3.29e-05.

The addition of an interaction term in Model D did not provide any significant improvement 
in terms of model performance with a slightly lower adjusted R squared value by 0.0009724
compared to the additive model. Also given that the p-value of the interaction term
was not statistically significant, Model B (additive)  should be the preferred model.

(f)
Using the plot() function that includes the residual plot :
```{r, echo=TRUE}
plot(model_b, which = 1)

plot(model_d, which = 1)
```
For both additive and multiplicative model, we can observe a violation of 
homoscedasticity because the variance is not constant throughout and shows
a pattern which also violates the linearity-assumption 
as we can see a visible pattern (curve pattern).

### Question 3
(a)
```{r, echo=TRUE}
# Creating data frame
habitat <- c("Coastal", "Coastal", "Offshore", "Offshore")
time <- c("Morning", "Evening", "Morning", "Evening")
mean_success <- c(5.2, 7.1, 6.5, 4.8)

forage_df <- data.frame(Habitat = habitat, Time = time, MeanSuccess = mean_success)
forage_df

# Create interaction plot (From Worksheet 17)
interaction.plot(x.factor = forage_df$Habitat, 
                 trace.factor = forage_df$Time, 
                 response = forage_df$MeanSuccess, 
                 type = "b",
                 main = "Interaction Plot: Habitat Type & Time of Day",
                 xlab = "Habitat Type",
                 ylab = "Mean Foraging Success",
                 trace.label = "Interactive labs",
                 pch=c(1,19), col = c("red", "blue"))

```
The cross lines in our interaction plot suggests that there exist an interaction
effect. The plot shows that the average foraging success is higher for morning
offshore foraging and evening coastal foraging.

(b)
Main Effect (Habitats)
$/ H_0 $ : There is no difference in mean foraging success between coastal and offshore habitats.
$/ H_a $ : There is a difference in mean foraging success between coastal and offshore habitats.

Main Effect (Time of Day)
$/ H_0 $ : There is no difference in mean foraging success between morning and evening.
$/ H_a $ : There is a difference in mean foraging success between morning and evening.

Interaction Effect
$/ H_0 $ : There is no interaction between habitat type and time of day
$/ H_a $ : There is an interaction between habitat type and time of day

(c)

Interaction Term (7.1 - 5.2) - (4.8 - 6.5) = 1.9 + 1.7 = 3.6
 
(d)



```{r, echo=TRUE}
# Sum of Squares
SS_habitat <- 10.3
SS_time <- 8.7
SS_interaction <- 12.5
SS_total <- 46.7
SS_error <- SS_total - SS_habitat - SS_time - SS_interaction

# Degree of Freedom
df_habitat = df_time = df_interaction = 1
df_error = 36
df_total = df_habitat + df_time + df_interaction + df_error

# Mean Square 
MS_habitat <- SS_habitat / df_habitat
MS_time <- SS_time / df_time
MS_interaction <- SS_interaction / df_interaction
MS_error <- SS_error / df_error

# F value
F_habitat <- MS_habitat / MS_error
F_time <- MS_time / MS_error
F_interaction <- MS_interaction / MS_error

anova_table <- data.frame(
  Source = c("Habitat", "Time", "Interaction", "Error", "Total"),
  SS = c(SS_habitat, SS_time, SS_interaction, SS_error, SS_total),
  df = c(df_habitat, df_time, df_interaction, df_error, df_total),
  MS = c(MS_habitat, MS_time, MS_interaction, MS_error, NA),
  F = c(F_habitat, F_time, F_interaction, NA, NA)
)
anova_table

```

(e)
```{r, echo=TRUE}
qf(0.95, df1 = 1, df2 = 36)
```
Since all F-values (Habitat 24, Time 20, Interaction 29) are greater than 4.11, 
so all effects are statistically significant at the 0.05 level.


### Question 4
(a)
```{r, echo=TRUE}
set.seed(123) 
coffee <- c(564.4, 498.2, 259.2, 303.3, 299.5, 307.2)

bootstrap_means <- numeric(1000)

# Bootstrapping
for (i in 1:1000) {
  bootstrap_sample <- sample(coffee, size = 6, replace = TRUE)
  bootstrap_means[i] <- mean(bootstrap_sample) # Compute the mean of the bootstrap sample
}
head(bootstrap_means)

# Sampling Distribution
hist(bootstrap_means,
     main = "Empirical Bootstrap Distribution of Mean", 
     xlab = "Bootstrap Sample Mean",
     breaks = 30)

```

(b)
```{r, echo=TRUE}
sd(bootstrap_means)
```
The bootstrap estimate's standard deviation tell us the variability of the sample mean 
across the 1000 bootstrap samples. It is significant to tell if our sample mean
is relatively stable (smaller sd) and if it is consistent across different samples
from the population.

(c)
```{r, echo=TRUE}
sorted_means <- sort(bootstrap_means)

lower_bound <- quantile(sorted_means, 0.025)
lower_bound

upper_bound <- quantile(sorted_means, 0.975)
upper_bound
```
There is a 95% chance that the true population mean lies within 289.2667 and
470.8187.

(d)
Null Hypothesis: The Mean Caffeine Content = 300mg
Alternative Hypothesis: The Mean Caffeine Content != 300 mg

```{r, echo=TRUE}
observed_mean <- mean(coffee)

# Using our previous question's bootstrapping 
observed_diff <- abs(observed_mean - 300)
extreme_count <- sum( abs(bootstrap_means - 300) >= observed_diff )
p_value <- extreme_count / 1000
p_value
```

Since our p-value is at 0.5, we reject the null hypothesis at 5% 
significance level. Hence, there is insufficient evidence to conclude that
the mean caffeine content differs from 300 mg.

(e)
```{r, echo=TRUE}
t_test_result <- t.test(coffee, mu = 300)
t_test_result
```
Using the one-sample t-test, we are assuming that the data follows a normal
distribution and comparing the observed sample mean to the null hypothesis 
value. Although our bootstrapping test does not have much assumptions, our conclusion
from our p-value does not differ with the one sample t-test where we reject
the null hypothesis.

(f)

